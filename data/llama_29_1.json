{"text":"Starter Tutorial Download data Set your OpenAI API key Load data and build an index Query your data Viewing Queries and Events Using Logging Storing your index   Getting Started Use Cases Understanding Optimizing Module Guides API Reference Community Contributing Changes Tip Make sure you ve followed the installation steps first This is our famous 5 lines of code starter example using OpenAI Want to use local models If you want to do our starter tutorial using only local models check out this tutorial instead This example uses the text of Paul Graham s essay What I Worked On This and many other examples can be found in the examples folder of our repo The easiest way to get it is to download it via this link and save it in a folder called data LlamaIndex uses OpenAI s gpt 3 5 turbo by default Make sure your API key is available to your code by setting it as an environment variable In MacOS and Linux this is the command and on Windows it is In the same folder where you created the data folder create a file called starter py file with the following This builds an index over the documents in the data folder which in this case just consists of the essay text but could contain many documents Your directory structure should look like this Add the following lines to starter py This creates an engine for Q A over your index and asks a simple question You should get back a response similar to the following The author wrote short stories and tried to program on an IBM 1401 Want to see what s happening under the hood Let s add some logging Add these lines to the top of starter py You can set the level to DEBUG for verbose output or use level logging INFO for less By default the data you just loaded is stored in memory as a series of vector embeddings You can save time and requests to OpenAI by saving the embeddings to disk That can be done with this line By default this will save the data to the directory storage but you can change that by passing a persist_dir parameter Of course you don t get the benefits of persisting unless you load the data So let s modify starter py to generate and store the index if it doesn t exist but load it if it does Now you can efficiently query to your heart s content But this is just the beginning of what you can do with LlamaIndex Next Steps learn more about the high level concepts tell me how to customize things curious about a specific module check out the guides on the left","link":"https://docs.llamaindex.ai/en/stable/getting_started/starter_example.html"}