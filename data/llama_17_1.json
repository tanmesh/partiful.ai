{"text":"Q A Types of question answering use cases Further examples What to do Where to search How to search  Getting Started Use Cases Understanding Optimizing Module Guides API Reference Community Contributing Changes One of the most common use cases for an LLM application is to answer questions about a set of documents LlamaIndex has rich support for many forms of question answering Q A has all sorts of sub types such as Semantic search finding data that matches not just your query terms but your intent and the meaning behind your question This is sometimes known as top k search Example of semantic search Summarization condensing a large amount of data into a short summary relevant to your current question Example of summarization Over documents LlamaIndex can pull in unstructured text PDFs Notion and Slack documents and more and index the data within them Example of search over documents Building a multi document agent over the LlamaIndex docs Over structured data if your data already exists in a SQL database as JSON or as any number of other structured formats LlamaIndex can query the data in these sources Searching Pandas tables Text to SQL Combine multiple sources is some of your data in Slack some in PDFs some in unstructured text LlamaIndex can combine queries across an arbitrary number of sources and combine them Example of combining multiple sources Route across multiple sources given multiple data sources your application can first pick the best source and then route the question to that source Example of routing across multiple sources Multi document queries some questions have partial answers in multiple data sources which need to be questioned separately before they can be combined Example of multi document queries For further examples of Q A use cases see our Q A section in Putting it All Together","link":"https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/root.html"}