{"text":"Recursive Retriever Document Agents Setup and Download Data Build Document Agent for each Document Build Composable Retriever over these Agents Running Example Queries   Getting Started Use Cases Understanding Optimizing Module Guides API Reference Community Contributing Changes  This guide shows how to combine recursive retrieval and document agents for advanced decision making over heterogeneous documents There are two motivating factors that lead to solutions for better retrieval Decoupling retrieval embeddings from chunk based synthesis Oftentimes fetching documents by their summaries will return more relevant context to queries rather than raw chunks This is something that recursive retrieval directly allows Within a document users may need to dynamically perform tasks beyond fact based question answering We introduce the concept of document agents agents that have access to both vector search and summary tools for a given document In this section we ll define imports and then download Wikipedia articles about different cities Each article is stored separately If you re opening this Notebook on colab you will probably need to install LlamaIndex Define LLM Service Context Callback Manager In this section we define document agents for each document First we define both a vector index for semantic search and summary index for summarization for each document The two query engines are then converted into tools that are passed to an OpenAI function calling agent This document agent can dynamically choose to perform semantic search or summarization within a given document We create a separate document agent for each city Now we define a set of summary nodes where each node links to the corresponding Wikipedia city article We then define a composable retriever query engine on top of these Nodes to route queries down to a given node which will in turn route it to the relevant document agent","link":"https://docs.llamaindex.ai/en/stable/examples/query_engine/recursive_retriever_agents.html"}