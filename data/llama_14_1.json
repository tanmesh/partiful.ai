{"text":"Router Query Engine Setup Global Models Load Data Define Summary Index and Vector Index over Same Data Define Query Engines and Set Metadata Define Router Query Engine PydanticSingleSelector LLMSingleSelector PydanticMultiSelector Getting Started Use Cases Understanding Optimizing Module Guides API Reference Community Contributing Changes  In this tutorial we define a custom router query engine that selects one out of several candidate query engines to execute a query If you re opening this Notebook on colab you will probably need to install LlamaIndex We first show how to convert a Document into a set of Nodes and insert into a DocumentStore There are several selectors available each with some distinct attributes The LLM selectors use the LLM to output a JSON that is parsed and the corresponding indexes are queried The Pydantic selectors currently only supported by gpt 4 0613 and gpt 3 5 turbo 0613 the default use the OpenAI Function Call API to produce pydantic selection objects rather than parsing raw JSON For each type of selector there is also the option to select 1 index to route to or multiple Use the OpenAI Function API to generate parse pydantic objects under the hood for the router selector Use OpenAI or any other LLM to parse generated JSON under the hood to select a sub index for routing In case you are expecting queries to be routed to multiple indexes you should use a multi selector The multi selector sends to query to multiple sub indexes and then aggregates all responses using a summary index to form a complete answer","link":"https://docs.llamaindex.ai/en/stable/examples/query_engine/RouterQueryEngine.html"}