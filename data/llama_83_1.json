{"text":"Image to Image Retrieval using CLIP embedding and image correlation reasoning using GPT4V Download images and texts from Wikipedia Build Multi Modal index and Vector Store to index both text and images from Wikipedia Plot input query image Retrieve images from Multi Modal Index given the image query Using Image Query Engine Plot images from Wikipedia 1 Image to Image Retrieval Results 2 GPT4V Reasoning Retrieved Images based on Input Image  Getting Started Use Cases Understanding Optimizing Module Guides API Reference Community Contributing Changes  In this notebook we show how to build a Image to Image retrieval using LlamaIndex with GPT4 V and CLIP LlamaIndex Image to Image Retrieval Images embedding index CLIP embeddings from OpenAI for images Framework LlamaIndex Steps Download texts images pdf raw files from Wikipedia pages Build Multi Modal index and vetor store for both texts and images Retrieve relevant images given a image query using Multi Modal Retriever Using GPT4V for reasoning the correlations between the input image and retrieved images Inside Query Engine there are few steps Retrieve relevant images based on input image Compose the image_qa_template by using the promt text Sending top k retrieved images and image_qa_template for GPT4V to answer synthesis","link":"https://docs.llamaindex.ai/en/stable/examples/multi_modal/image_to_image_retrieval.html"}