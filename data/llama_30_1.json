{"text":"Query Engines Pydantic Outputs Usage Pattern Modules   Getting Started Use Cases Understanding Optimizing Module Guides API Reference Community Contributing Changes Using index as_query_engine and it s underlying RetrieverQueryEngine we can support structured pydantic outputs without an additional LLM calls in contrast to a typical output parser Every query engine has support for integrated structured responses using the following response_modes in RetrieverQueryEngine refine compact tree_summarize accumulate beta requires extra parsing to convert to objects compact_accumulate beta requires extra parsing to convert to objects Under the hood this uses OpenAIPydanitcProgam or LLMTextCompletionProgram depending on which LLM you ve setup If there are intermediate LLM responses i e during refine or tree_summarize with multiple LLM calls the pydantic object is injected into the next LLM prompt as a JSON object First you need to define the object you want to extract Then you create your query engine Lastly you can get a response and inspect the output Detailed usage is available in the notebooks below","link":"https://docs.llamaindex.ai/en/stable/module_guides/querying/structured_outputs/query_engine.html"}