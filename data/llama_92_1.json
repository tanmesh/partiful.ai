{"text":"Single Turn Multi Function Calling OpenAI Agents Setup Sync mode Async mode Example from OpenAI docs Conclusion   Getting Started Use Cases Understanding Optimizing Module Guides API Reference Community Contributing Changes  With the latest OpenAI API v 1 1 0 users can now execute multiple function calls within a single turn of User and Agent dialogue We ve updated our library to enable this new feature as well and in this notebook we ll show you how it all works NOTE OpenAI refers to this as Parallel function calling but the current implementation doesn t invoke parallel computations of the multiple function calls So it s parallelizable function calling in terms of our current implementation If you ve seen any of our previous notebooks on OpenAI Agents then you re already familiar with the cookbook recipe that we have to follow here But if not or if you fancy a refresher then all we need to do at a high level are the following steps Define a set of tools we ll use FunctionTool since Agents work with tools Define the LLM for the Agent Define a OpenAIAgent Here s an example straight from the OpenAI docs on Parallel function calling Their example gets this done in 76 lines of code whereas with the llama_index library you can get that down to about 18 lines All of the above function calls that the Agent has done above were in a single turn of dialogue between the Assistant and the User What s interesting is that an older version of GPT 3 5 is not quite advanced enough compared to is successor it will do the above task in 3 separate turns For the sake of demonstration here it is below And so as you can see the llama_index library can handle multiple function calls as well as a single function call within a single turn of dialogue between the user and the OpenAI agent","link":"https://docs.llamaindex.ai/en/stable/examples/agent/openai_agent_parallel_function_calling.html"}