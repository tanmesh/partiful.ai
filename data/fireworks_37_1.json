{"text":"Querying vision language modelsUsing the web consoleUsing the APIAdvanced optionsManaging imagesCalculating costFAQ GuidesSTRUCTURED RESPONSESEnterprise GuidesDocumentationChat Completions APICompletions APIAPI LimitationsModel LimitationsCan I fine tune the image capabilities with FireLlava Can FireLlava generate images What type of files can I upload Is there a limit to the size of the image I can upload What is the retention policy for the images I upload How do rate limits work with FireLlava Can FireLlava understand image metadata Overriding the system prompt  Please refer to https readme fireworks ai docs querying text models for accessing the web console Both completions API and chat completions API are supported However we would recommend users to stick to chat completions API for simplicity All vision language models should have a conversation config and have chat completions API enabled These models are typically tuned with a specific conversation styles for which they perform best For example FireLLaVA models use the following template SYSTEM system message USER user message ASSISTANT The substring is a special token that we insert into the prompt to allow the model to figure out where to put the image In general we recommend users use the chat completions API whenever possible to avoid common prompt formatting errors Even small errors like misplaced whitespace may result in poor model performance When used as a text only language model you can also just call API without the nested message content field see https readme fireworks ai docs querying text models for details Here are some examples of calling the chat completions API In the above example we are providing images by providing the URL to the images Alternatively you can also provide the string representation of the base64 encoding of the images prefixed with MIME types For example A conversation style may include a default system prompt For example the llava chat style uses the default Llava prompt A chat between a curious user and an artificial intelligence The assistant gives helpful detailed and polite answers to the user s questions For styles that support a system prompt you may override this prompt by setting the first message with role system For example To completely omit the system prompt you can set content to the empty string For more details please refer to the Overriding the system prompt section of https readme fireworks ai docs querying text models Advanced users can also query the completions API directly Users will need to manually insert the image token where appropriate and supply the list of images as an ordered list this is true for FireLLaVA model but may be subject to change for future vision language models For example Right now we impose certain limit on the completions API and chat completions API as follows At the moment FireLLaVA is the only VLM available and owing to the nature of the model and how it was trained model performance may degrade when there are multiple images in the same conversation Please refer to https readme fireworks ai docs querying text models for more advanced options and generation parameters The Chat Completions API is not stateful That means you have to manage the messages including images you pass to the model yourself However we try to cache the image download as much as we can to save latency on model download For long running conversations we suggest passing images via URL s instead of base64 The latency of the model can also be improved by downsizing your images ahead of time to be less than the maximum size they are expected them to be For FireLLaVA 13B each image is treated as 576 prompt tokens The pricing is otherwise identical to a 13B text models For more information please refer to our our pricing page here We currently do not charge separately for high resolution images and low resolution images they all cost 576 tokens Not right now but we are working on integrating FireLlava with fine tuning If you are interested please reach out to us via Discord No We have a list of models deployed on our platform that is StableDiffusion based Please give these models a try and let us know how it goes We currently support png jpg jpeg gif bmp tiff and ppm format images Currently our API is restricted to 10MB for the whole request so the image sent through request in base64 encoding will need to be smaller than 10MB when converted to base64 encoding If you are using URLs then each image need to be smaller than 5MB We do not persist the images longer than the server lifetime and will be deleted automatically FireLlava is rate limited like all of our other LLM models which depends on which tier of rate limiting you are at For more information please check out https readme fireworks ai page pricing No If you have image metadata that you want the model to understand please provide them through the prompt Updated about 1 month ago","link":"https://readme.fireworks.ai/docs/querying-vision-language-models"}